{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST PyTorch",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPeoaJ+Rz5bIpri56bVTMIu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sameeragrawal536/PyTorch-Neural-Network/blob/main/MNIST_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import time\n",
        "import math"
      ],
      "metadata": {
        "id": "F9bXSyD_4DkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "#Loading training and testing data\n",
        "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform = transformer)\n",
        "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform = transformer)"
      ],
      "metadata": {
        "id": "AsCUVyKg4H3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  #Architecture taken from Sentdex PyTorch tutorial\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3)\n",
        "    self.maxPool1 = nn.MaxPool2d((2, 2))\n",
        "    self.dropout1 = nn.Dropout(0.5)\n",
        "    self.fc1 = nn.Linear(13*13*32, 128)\n",
        "    self.fc2 = nn.Linear(128, 64)\n",
        "    self.fc3 = nn.Linear(64, 10)\n",
        "  \n",
        "  #Softmax at the end to scale values to sum to 1\n",
        "  def forward(self, input):\n",
        "    first = torch.relu(self.conv1(input))\n",
        "    small = self.maxPool1(first)\n",
        "    #print(small.shape)\n",
        "    droppedout = self.dropout1(small)\n",
        "    #print(droppedout.shape)\n",
        "    droppout2 = droppedout.view(-1, 13*13*32)\n",
        "    l1 = torch.relu(self.fc1(droppout2))                \n",
        "    l2 = torch.relu(self.fc2(l1))\n",
        "    output = torch.softmax((self.fc3(l2)), dim = 1)\n",
        "    return torch.log(output + 1e-10)"
      ],
      "metadata": {
        "id": "f-ui4hOfKuAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neuralNetwork = Net()\n",
        "\n",
        "#Creating train/test set\n",
        "trainloader = torch.utils.data.DataLoader(mnist_trainset, batch_size=1, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(mnist_testset, batch_size=1, shuffle=True)\n",
        "\n",
        "#This loss was used because labels are not 1 hot encoded\n",
        "losscalc = nn.NLLLoss()\n",
        "optimizer = optim.Adam(neuralNetwork.parameters(), lr = 0.001)"
      ],
      "metadata": {
        "id": "Jkf_WXmT4TM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(15):\n",
        "  accuracy = 0\n",
        "  j = 0\n",
        "  for data in trainloader:\n",
        "    inputs, labels = data\n",
        "    #print(labels.shape)\n",
        "    #print(inputs.shape)\n",
        "    optimizer.zero_grad()\n",
        "    #Reshaping data, flattening it\n",
        "    #print(inputs.shape)\n",
        "    outputs = neuralNetwork(inputs)\n",
        "    #print(outputs.shape)\n",
        "   # print(outputs.shape)\n",
        "    loss = losscalc(outputs, labels)\n",
        "\n",
        "    #Backpropogation + Gradient Descent\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    index = 0\n",
        "    for i in range(10):\n",
        "      if outputs[0][index].item() < outputs[0][i].item():\n",
        "        index = i\n",
        "    if index == labels[0].item():\n",
        "      accuracy += 1\n",
        "    j += 1\n",
        "    #print(j)\n",
        "  print(\"loss \" + str(math.exp(loss)))\n",
        "  print(\"accuracy \" + str(accuracy/float(j)))\n",
        "\n",
        "print(\"Done training!\")"
      ],
      "metadata": {
        "id": "uO_ta_ba4Y_h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
